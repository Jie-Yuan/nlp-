{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../dataset/cnews/cnews.train.txt',sep='\\t',names=['label','content'],encoding='UTF-8',engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>体育</td>\n",
       "      <td>马晓旭意外受伤让国奥警惕 无奈大雨格外青睐殷家军记者傅亚雨沈阳报道 来到沈阳，国奥队依然没有...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>体育</td>\n",
       "      <td>商瑞华首战复仇心切 中国玫瑰要用美国方式攻克瑞典多曼来了，瑞典来了，商瑞华首战求3分的信心也...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>体育</td>\n",
       "      <td>冠军球队迎新欢乐派对 黄旭获大奖张军赢下PK赛新浪体育讯12月27日晚，“冠军高尔夫球队迎新...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>体育</td>\n",
       "      <td>辽足签约危机引注册难关 高层威逼利诱合同笑里藏刀新浪体育讯2月24日，辽足爆发了集体拒签风波...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>体育</td>\n",
       "      <td>揭秘谢亚龙被带走：总局电话骗局 复制南杨轨迹体坛周报特约记者张锐北京报道  谢亚龙已经被公安...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            content\n",
       "0    体育  马晓旭意外受伤让国奥警惕 无奈大雨格外青睐殷家军记者傅亚雨沈阳报道 来到沈阳，国奥队依然没有...\n",
       "1    体育  商瑞华首战复仇心切 中国玫瑰要用美国方式攻克瑞典多曼来了，瑞典来了，商瑞华首战求3分的信心也...\n",
       "2    体育  冠军球队迎新欢乐派对 黄旭获大奖张军赢下PK赛新浪体育讯12月27日晚，“冠军高尔夫球队迎新...\n",
       "3    体育  辽足签约危机引注册难关 高层威逼利诱合同笑里藏刀新浪体育讯2月24日，辽足爆发了集体拒签风波...\n",
       "4    体育  揭秘谢亚龙被带走：总局电话骗局 复制南杨轨迹体坛周报特约记者张锐北京报道  谢亚龙已经被公安..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['，', '。', '/', ' ', ' ', '！', '■', '#', '{', '}', '（', '）', '[', ']', '【', '】', '“', '”', '+', '-', '_', '(', ')', '~', '`', '*', '－', '—', '～', '•', '●', '⊙', '=', '!', '□', '／', '@', '：', '？', '?', '￥', '$', '、', '‘', '’', \"'\", ';', ',', '.', ':', ';', '\"', '；', '的', '了', '呢', '么', '啊', '们', '你', '我', '它', '他', '她', '你们', '我们', '他们', '她们', '它们', '这', '那', '能', '可', '也', '来', '让', '又', '下', '上', '中', '在', '《', '》', '…', '·', '吧', '吗', '是', ' ', '有']\n"
     ]
    }
   ],
   "source": [
    "def get_stopwords(path):\n",
    "    with open(path,'r',encoding='utf-8') as f:\n",
    "        stopwords = f.read().split('\\n')\n",
    "    return stopwords\n",
    "\n",
    "stopwords = get_stopwords('./stopwords.txt')\n",
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "马晓旭 意外 受伤 国奥 警惕 无奈 大雨 格外 青睐 殷家 军 记者 傅亚雨 沈阳 报道 来到 沈阳 国奥队 依然 没有 摆脱 雨水 困扰 7 月 31 日 下午 6 点 国奥队 日常 训练 再度 受到 大雨 干扰 无奈 之下 队员 只 慢跑 25 分钟 就 草草收场 31 日 上午 10 点 国奥队 奥体中心 外场 训练 时候 天 就是 阴沉沉 气象预报 显示 当天 下午 沈阳 就 大雨 但 幸好 队伍 上午 训练 并 没有 受到 任何 干扰 下午 6 点 当 球队 抵达 训练场 时 大雨 已经 几个 小时 而且 丝毫 没有 停下来 意思 抱 着 试一试 态度 球队 开始 当天 下午 例行 训练 25 分钟 过去 天气 没有 任何 转好 迹象 为了 保护 球员 国奥队 决定 中止 当天 训练 全队 立即 返回 酒店 雨 训练 对 足球队 来说 并 不是 什么 稀罕 事 但 奥运会 即将 开始 之前 全队 变得 娇贵 沈阳 最后 一周 训练 国奥队 首先 要 保证 现有 球员 不再 出现意外 伤病 情况 以免 影响 正式 比赛 因此 这一 阶段 控制 训练 受伤 控制 感冒 等 疾病 出现 被 队伍 放在 相当 重要 位置 而 抵达 沈阳 之后 后卫 冯萧霆 就 一直 没有 训练 冯萧霆 7 月 27 日 长春 患上 感冒 因此 没有 参加 29 日 跟 塞尔维亚 热身赛 队伍 介绍 说 冯萧霆 并 没有 出现 发烧 症状 但 为了 安全 起 见 两天 还是 静养 休息 等 感冒 彻底 好 之后 再 恢复 训练 由于 冯萧霆 这个 例子 因此 国奥队 对雨中 训练 就 显得 特别 谨慎 主要 担心 球员 受凉 而 引发 感冒 造成 非战斗 减员 而 女足 队员 马晓旭 热身赛 受伤 导致 无缘 奥运 前科 沈阳 国奥队 现在 格外 警惕 训练 不断 嘱咐 队员 要 注意 动作 不能 再出 这样 事情 一位 工作人员 表示 从 长春 到 沈阳 雨水 一路 伴随 着 国奥队 邪 走 到 哪儿 雨 就 到 哪儿 长春 几次 训练 都 被 大雨 给 搅和 没想到 沈阳 碰到 这种 事情 一位 国奥 球员 对 雨水 青睐 有些 不解\n"
     ]
    }
   ],
   "source": [
    "contents = np.array(train_data['content'])\n",
    "prepross_data = []\n",
    "for line in contents:\n",
    "    prepross_data.append(' '.join([i for i in jieba.lcut(line) if i not in stopwords]))\n",
    "print(prepross_data[0])\n",
    "\n",
    "with open('./after_preprocess_traindata.txt','w',encoding='utf-8') as f:\n",
    "    f.write('\\n'.join(prepross_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3_2018.12\\envs\\python36\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 216, got 192\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_model = TfidfVectorizer(max_features=5000,max_df=0.8)\n",
    "res = tfidf_model.fit_transform(prepross_data)\n",
    "# print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-97e95028ac01>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mencoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_data' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(train_data['label'])\n",
    "print(y)\n",
    "print(encoder.classes_)\n",
    "print(encoder.inverse_transform([0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\tadsh\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.719 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_csv('../dataset/cnews/cnews.test.txt',sep='\\t',names=['label','content'],encoding='UTF-8',engine='python')\n",
    "# test_y = encoder.transform(test_data['label'])\n",
    "\n",
    "test_x = []\n",
    "for line in test_data['content']:\n",
    "    test_x.append(' '.join([i for i in jieba.lcut(line) if i not in stopwords]))\n",
    "\n",
    "with open('./after_preprocess_testdata.txt','w',encoding='utf-8') as f:\n",
    "    f.write('\\n'.join(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9205\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()\n",
    "nb.fit(res,y)\n",
    "test_x = tfidf_model.transform(test_x)\n",
    "pred_y = nb.predict(test_x)\n",
    "acc = np.sum(pred_y == test_y)/len(test_y)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9205\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gs = GaussianNB()\n",
    "gs.fit(res.toarray(),y)\n",
    "pred = gs.predict(test_x.toarray())\n",
    "acc = np.sum(pred_y == test_y)/len(test_y)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start train svc.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC(kernel='rbf',gamma=0.1, C=0.1)\n",
    "print('start train svc.')\n",
    "svc.fit(res.toarray(),y)\n",
    "print('end train svc.')\n",
    "test_x = tfidf_model.transform(test_x)\n",
    "pred_y = nb.predict(test_x.toarray())\n",
    "acc = np.sum(pred_y == test_y)/len(test_y)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class SelectKBest in module sklearn.feature_selection.univariate_selection:\n",
      "\n",
      "class SelectKBest(_BaseFilter)\n",
      " |  Select features according to the k highest scores.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <univariate_feature_selection>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  score_func : callable\n",
      " |      Function taking two arrays X and y, and returning a pair of arrays\n",
      " |      (scores, pvalues) or a single array with scores.\n",
      " |      Default is f_classif (see below \"See also\"). The default function only\n",
      " |      works with classification tasks.\n",
      " |  \n",
      " |  k : int or \"all\", optional, default=10\n",
      " |      Number of top features to select.\n",
      " |      The \"all\" option bypasses selection, for use in a parameter search.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  scores_ : array-like, shape=(n_features,)\n",
      " |      Scores of features.\n",
      " |  \n",
      " |  pvalues_ : array-like, shape=(n_features,)\n",
      " |      p-values of feature scores, None if `score_func` returned only scores.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.datasets import load_digits\n",
      " |  >>> from sklearn.feature_selection import SelectKBest, chi2\n",
      " |  >>> X, y = load_digits(return_X_y=True)\n",
      " |  >>> X.shape\n",
      " |  (1797, 64)\n",
      " |  >>> X_new = SelectKBest(chi2, k=20).fit_transform(X, y)\n",
      " |  >>> X_new.shape\n",
      " |  (1797, 20)\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  Ties between features with equal scores will be broken in an unspecified\n",
      " |  way.\n",
      " |  \n",
      " |  See also\n",
      " |  --------\n",
      " |  f_classif: ANOVA F-value between label/feature for classification tasks.\n",
      " |  mutual_info_classif: Mutual information for a discrete target.\n",
      " |  chi2: Chi-squared stats of non-negative features for classification tasks.\n",
      " |  f_regression: F-value between label/feature for regression tasks.\n",
      " |  mutual_info_regression: Mutual information for a continuous target.\n",
      " |  SelectPercentile: Select features based on percentile of the highest scores.\n",
      " |  SelectFpr: Select features based on a false positive rate test.\n",
      " |  SelectFdr: Select features based on an estimated false discovery rate.\n",
      " |  SelectFwe: Select features based on family-wise error rate.\n",
      " |  GenericUnivariateSelect: Univariate feature selector with configurable mode.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      SelectKBest\n",
      " |      _BaseFilter\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.feature_selection.base.SelectorMixin\n",
      " |      abc.NewBase\n",
      " |      sklearn.base.TransformerMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, score_func=<function f_classif at 0x00000232727C27B8>, k=10)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from _BaseFilter:\n",
      " |  \n",
      " |  fit(self, X, y)\n",
      " |      Run score function on (X, y) and get the appropriate features.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = [n_samples, n_features]\n",
      " |          The training input samples.\n",
      " |      \n",
      " |      y : array-like, shape = [n_samples]\n",
      " |          The target values (class labels in classification, real numbers in\n",
      " |          regression).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.feature_selection.base.SelectorMixin:\n",
      " |  \n",
      " |  get_support(self, indices=False)\n",
      " |      Get a mask, or integer index, of the features selected\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      indices : boolean (default False)\n",
      " |          If True, the return value will be an array of integers, rather\n",
      " |          than a boolean mask.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      support : array\n",
      " |          An index that selects the retained features from a feature vector.\n",
      " |          If `indices` is False, this is a boolean array of shape\n",
      " |          [# input features], in which an element is True iff its\n",
      " |          corresponding feature is selected for retention. If `indices` is\n",
      " |          True, this is an integer array of shape [# output features] whose\n",
      " |          values are indices into the input feature vector.\n",
      " |  \n",
      " |  inverse_transform(self, X)\n",
      " |      Reverse the transformation operation\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array of shape [n_samples, n_selected_features]\n",
      " |          The input samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_r : array of shape [n_samples, n_original_features]\n",
      " |          `X` with columns of zeros inserted where features would have\n",
      " |          been removed by `transform`.\n",
      " |  \n",
      " |  transform(self, X)\n",
      " |      Reduce X to the selected features.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array of shape [n_samples, n_features]\n",
      " |          The input samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_r : array of shape [n_samples, n_selected_features]\n",
      " |          The input samples with only the selected features.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.TransformerMixin:\n",
      " |  \n",
      " |  fit_transform(self, X, y=None, **fit_params)\n",
      " |      Fit to data, then transform it.\n",
      " |      \n",
      " |      Fits transformer to X and y with optional parameters fit_params\n",
      " |      and returns a transformed version of X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : numpy array of shape [n_samples, n_features]\n",
      " |          Training set.\n",
      " |      \n",
      " |      y : numpy array of shape [n_samples]\n",
      " |          Target values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_new : numpy array of shape [n_samples, n_features_new]\n",
      " |          Transformed array.\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
