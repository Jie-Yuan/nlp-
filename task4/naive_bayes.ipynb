{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取训练数据，测试数据\n",
    "train_data = []\n",
    "with open('./after_preprocess_traindata.txt',encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        train_data.append(line.strip())\n",
    "\n",
    "test_data = []\n",
    "with open('./after_preprocess_testdata.txt',encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        test_data.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取标签编码\n",
    "df1 = pd.read_csv('../dataset/cnews/cnews.train.txt',sep='\\t',names=['label','content'],encoding='UTF-8',engine='python')\n",
    "df2 = pd.read_csv('../dataset/cnews/cnews.test.txt',sep='\\t',names=['label','content'],encoding='UTF-8',engine='python')\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "train_y = encoder.fit_transform(df1['label'])\n",
    "test_y = encoder.transform(df2['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tfidf 筛选前6000个特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取tfidf_transformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_transformer = TfidfVectorizer(max_features=6000)\n",
    "tfidf_transformer.fit(train_data)\n",
    "\n",
    "# 将train_data，test_data转换成tfidf矩阵\n",
    "train_x = tfidf_transformer.transform(train_data)\n",
    "test_x = tfidf_transformer.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 训练朴素贝叶斯\n",
    "gs = GaussianNB()\n",
    "gs.fit(train_x.toarray(),train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000,) (10000,) (10000, 6000)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99      1000\n",
      "           1       0.89      0.94      0.92      1000\n",
      "           2       0.90      0.39      0.55      1000\n",
      "           3       0.64      0.85      0.73      1000\n",
      "           4       0.84      0.88      0.86      1000\n",
      "           5       0.91      0.91      0.91      1000\n",
      "           6       0.89      0.87      0.88      1000\n",
      "           7       0.94      0.94      0.94      1000\n",
      "           8       0.90      0.97      0.94      1000\n",
      "           9       0.88      0.96      0.92      1000\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     10000\n",
      "   macro avg       0.88      0.87      0.86     10000\n",
      "weighted avg       0.88      0.87      0.86     10000\n",
      "\n",
      "[[984   6   0   2   1   0   0   4   2   1]\n",
      " [  0 944   0   1  12  24   1  18   0   0]\n",
      " [  0  13 394 381  53  42  28   7  36  46]\n",
      " [  0  12   8 846  29   6  37   1   5  56]\n",
      " [  0  18   4   4 881   4  34   9  29  17]\n",
      " [  0  39  29   0  17 908   0   3   4   0]\n",
      " [  0  11   0  44  45   0 873   2  10  15]\n",
      " [  0  19   1   1  11  12   0 938  18   0]\n",
      " [  0   0   3   3   1   5   0  13 974   1]\n",
      " [  0   0   0  30   1   0   8   0   0 961]]\n",
      "acc 0.8703\n"
     ]
    }
   ],
   "source": [
    "# 测试\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "pred = gs.predict(test_x.toarray())\n",
    "print(pred.shape,test_y.shape, test_x.shape)\n",
    "report = classification_report(test_y,pred)\n",
    "print(report)\n",
    "\n",
    "mat = confusion_matrix(test_y,pred)\n",
    "print(mat)\n",
    "\n",
    "acc = np.sum(pred == test_y)/len(test_y)\n",
    "print('acc', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 下面是先转成tfidf，然后用互信息选取6000个特征。但是筛选的速度很慢，最终预测结果也比直接tfidf筛选略低"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--1--\n",
      "--2--\n",
      "--3--\n",
      "--4--\n",
      "(50000, 6000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "tfidf_transformer2 = TfidfVectorizer()\n",
    "tfidf_transformer2.fit(train_data)\n",
    "print('--1--')\n",
    "# 将train_data，test_data转换成tfidf矩阵\n",
    "train2_x = tfidf_transformer2.transform(train_data)\n",
    "print('--2--')\n",
    "test2_x = tfidf_transformer2.transform(test_data)\n",
    "print('--3--')\n",
    "selector = SelectKBest(mutual_info_classif, k=6000)\n",
    "print('--4--')\n",
    "new_train_x = selector.fit_transform(train2_x,train_y)\n",
    "print(new_train_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99      1000\n",
      "           1       0.89      0.93      0.91      1000\n",
      "           2       0.87      0.31      0.46      1000\n",
      "           3       0.62      0.84      0.71      1000\n",
      "           4       0.81      0.86      0.83      1000\n",
      "           5       0.91      0.91      0.91      1000\n",
      "           6       0.89      0.88      0.89      1000\n",
      "           7       0.92      0.94      0.93      1000\n",
      "           8       0.91      0.96      0.93      1000\n",
      "           9       0.86      0.95      0.90      1000\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     10000\n",
      "   macro avg       0.87      0.86      0.85     10000\n",
      "weighted avg       0.87      0.86      0.85     10000\n",
      "\n",
      "[[984   6   0   0   2   0   1   5   2   0]\n",
      " [  0 932   0   3  15  26   2  17   5   0]\n",
      " [  3   8 314 421  83  34  25  15  35  62]\n",
      " [  0  11  11 839  31   2  49   1   2  54]\n",
      " [  1  25   3   5 860  11  25  22  31  17]\n",
      " [  0  38  24   1  18 912   1   4   2   0]\n",
      " [  0   9   0  44  42   0 878   1   9  17]\n",
      " [  0  19   1   1  11  18   1 935  14   0]\n",
      " [  0   1   8   3   3   4   0  19 961   1]\n",
      " [  0   0   0  45   2   0   2   0   0 951]]\n",
      "acc 0.8566\n"
     ]
    }
   ],
   "source": [
    "gs2 = GaussianNB()\n",
    "gs2.fit(new_train_x.toarray(),train_y)\n",
    "\n",
    "new_test_x = selector.transform(test2_x)\n",
    "pred = gs2.predict(new_test_x.toarray())\n",
    "\n",
    "report = classification_report(test_y,pred)\n",
    "print(report)\n",
    "\n",
    "mat = confusion_matrix(test_y,pred)\n",
    "print(mat)\n",
    "\n",
    "acc = np.sum(pred == test_y)/len(test_y)\n",
    "print('acc', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用SVM来进行分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc_model = SVC()\n",
    "print('start fit.')\n",
    "svc_model.fit(train_x,train_y)\n",
    "print('end fit.')\n",
    "\n",
    "pred = svc_model.predict(test_x.toarray())\n",
    "\n",
    "report = classification_report(test_y,pred)\n",
    "print(report)\n",
    "\n",
    "mat = confusion_matrix(test_y,pred)\n",
    "print(mat)\n",
    "\n",
    "acc = np.sum(pred == test_y)/len(test_y)\n",
    "print('acc', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
