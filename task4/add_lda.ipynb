{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取训练数据，测试数据\n",
    "train_data = []\n",
    "with open('./after_preprocess_traindata.txt',encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        train_data.append(line.strip())\n",
    "\n",
    "test_data = []\n",
    "with open('./after_preprocess_testdata.txt',encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        test_data.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取标签编码\n",
    "df1 = pd.read_csv('../dataset/cnews/cnews.train.txt',sep='\\t',names=['label','content'],encoding='UTF-8',engine='python')\n",
    "df2 = pd.read_csv('../dataset/cnews/cnews.test.txt',sep='\\t',names=['label','content'],encoding='UTF-8',engine='python')\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "train_y = encoder.fit_transform(df1['label'])\n",
    "test_y = encoder.transform(df2['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 接着我们要把词转化为词频向量（词袋），注意由于LDA是基于词频统计的，因此一般不用TF-IDF来做文档特征。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "bow = cv.fit_transform(train_data)\n",
    "# print(bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--4--\n",
      "(50000, 5000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "selector = SelectKBest(mutual_info_classif, k=5000)\n",
    "new_train_x = selector.fit_transform(bow,train_y)\n",
    "print(new_train_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 保存剩余筛选器模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pkl = pickle.dumps(selector)\n",
    "with open('./selector_model.pkl','wb') as f:\n",
    "    f.write(pkl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 测试读取筛选器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 5000)\n"
     ]
    }
   ],
   "source": [
    "with open('./selector_model.pkl','rb') as f:\n",
    "    model = pickle.loads(f.read())\n",
    "new_train_x_test = model.transform(bow)\n",
    "print(new_train_x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 开始创建LDA模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "lda = LatentDirichletAllocation(n_components=150, learning_offset=50.,max_iter=1000,random_state=1)\n",
    "lda.fit(new_train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
